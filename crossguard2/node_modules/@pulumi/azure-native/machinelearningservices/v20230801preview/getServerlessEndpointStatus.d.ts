import * as pulumi from "@pulumi/pulumi";
export declare function getServerlessEndpointStatus(args: GetServerlessEndpointStatusArgs, opts?: pulumi.InvokeOptions): Promise<GetServerlessEndpointStatusResult>;
export interface GetServerlessEndpointStatusArgs {
    /**
     * Serverless Endpoint name.
     */
    name: string;
    /**
     * The name of the resource group. The name is case insensitive.
     */
    resourceGroupName: string;
    /**
     * Name of Azure Machine Learning workspace.
     */
    workspaceName: string;
}
export interface GetServerlessEndpointStatusResult {
    /**
     * The model-specific metrics from the backing inference endpoint.
     */
    readonly metrics: {
        [key: string]: string;
    };
}
export declare function getServerlessEndpointStatusOutput(args: GetServerlessEndpointStatusOutputArgs, opts?: pulumi.InvokeOutputOptions): pulumi.Output<GetServerlessEndpointStatusResult>;
export interface GetServerlessEndpointStatusOutputArgs {
    /**
     * Serverless Endpoint name.
     */
    name: pulumi.Input<string>;
    /**
     * The name of the resource group. The name is case insensitive.
     */
    resourceGroupName: pulumi.Input<string>;
    /**
     * Name of Azure Machine Learning workspace.
     */
    workspaceName: pulumi.Input<string>;
}
